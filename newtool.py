import streamlit as st
import pandas as pd
from huggingface_hub import list_models
from datetime import datetime, timezone
import re
import time

# --- 1) í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="HF ëª¨ë¸ íƒìƒ‰ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ¤—",
    layout="wide",
)

# --- 2) ë°ì´í„° ë¡œë”© & ìºì‹± ---
@st.cache_data(ttl=3600)
def search_models_on_hub(query: str, authors: tuple, sort: str, text_gen_only: bool):
    """
    ì‚¬ìš©ì í•„í„° ì¡°ê±´ì„ ë°”íƒ•ìœ¼ë¡œ Hugging Face Hub APIë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        sort_map = {
            "ë‹¤ìš´ë¡œë“œìˆœ (Downloads)": "downloads",
            "ì¸ê¸°ìˆœ (Likes)": "likes",
            "ìµœì‹ ìˆœ (Created At)": "lastModified",
            "íŒŒë¼ë¯¸í„° í¬ê¸°ìˆœ (Parameter Size)": "downloads"  # APIì—ì„œëŠ” downloadsë¡œ ê°€ì ¸ì˜¤ê³  í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì¬ì •ë ¬
        }
        api_sort = sort_map.get(sort, "downloads")
        api_filter = "text-generation" if text_gen_only else None

        # âœ… 1. ë‹¤ì¤‘ íšŒì‚¬ ì¡°íšŒ ì˜¤ë¥˜ í•´ê²°: ê°œë³„ ì¡°íšŒ í›„ ë³‘í•©
        all_models_list = []
        target_authors = list(authors) if authors else [None]
        
        progress_bar = st.progress(0, text="ëª¨ë¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        for i, author in enumerate(target_authors):
            current_query = query if i == 0 or author is None else None

            models_chunk = list(list_models(
                search=current_query,
                author=author,
                filter=api_filter,
                sort=api_sort,
                limit=1000,
                full=True,
            ))
            all_models_list.extend(models_chunk)
            progress_bar.progress((i + 1) / len(target_authors), text=f"'{author or 'ì „ì²´'}' ëª¨ë¸ ì •ë³´ ë¡œë”© ì™„ë£Œ...")
        
        progress_bar.empty()

        # ì¤‘ë³µ ì œê±°
        seen_ids = set()
        unique_models = []
        for model in all_models_list:
            if model.modelId not in seen_ids:
                unique_models.append(model)
                seen_ids.add(model.modelId)
        
        models_list = unique_models

        processed = []
        for m in models_list:
            created_raw = getattr(m, "created_at", None) or getattr(m, "createdAt", None) or getattr(m, "lastModified", None)
            processed.append({
                "modelId": getattr(m, "modelId", None),
                "author": getattr(m, "author", None),
                "createdAt": created_raw,
                "downloads": getattr(m, "downloads", 0),
                "likes": getattr(m, "likes", 0),
                "pipeline_tag": getattr(m, "pipeline_tag", "N/A"),
                "tags": getattr(m, "tags", []) or [],
            })

        df = pd.DataFrame(processed)
        df["createdAt"] = pd.to_datetime(df["createdAt"], errors="coerce", utc=True)
        df["param_size"] = df.apply(lambda row: extract_param_size(row["tags"]) or extract_param_size_from_name(row["modelId"]), axis=1)
        df["param_size_numeric"] = df["param_size"].apply(param_size_to_numeric)
        return df

    except Exception as e:
        st.error(f"ëª¨ë¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()


# --- 3) tag ì¶”ì¶œ/íŒë³„ í•¨ìˆ˜ ---
def extract_license(tags):
    for t in tags or []:
        if isinstance(t, str) and t.startswith("license:"): return t.split(":", 1)[-1]
    return None

def extract_task_from_tags(tags):
    KNOWN_TASKS = {"text-generation", "image-classification", "translation", "summarization", "question-answering"}
    for t in tags or []:
        if isinstance(t, str) and t in KNOWN_TASKS: return t
    return None

def param_size_to_numeric(param_size):
    if not param_size: return 0
    param_size = param_size.upper()
    moe_match = re.match(r"(\d+)X(\d+(?:\.\d+)?)B", param_size)
    if moe_match: return float(moe_match.group(1)) * float(moe_match.group(2))
    normal_match = re.match(r"(\d+(?:\.\d+)?)B", param_size)
    if normal_match: return float(normal_match.group(1))
    return 0

def extract_param_size_from_name(model_id):
    if not isinstance(model_id, str): return None
    match = re.search(r"[-_]?(\d+(?:\.\d+)?)[bB](?:[-_]|$)", model_id)
    if match: return f"{match.group(1)}B"
    match = re.search(r"[-_]?(\d+)x(\d+(?:\.\d+)?)[bB](?:[-_]|$)", model_id)
    if match: return f"{match.group(1)}x{match.group(2)}B"
    return None

def extract_param_size(tags):
    for t in tags or []:
        if isinstance(t, str):
            if re.match(r"^\d+(\.\d+)?[bB]$", t, re.IGNORECASE): return t.upper()
            if re.match(r"^\d+x\d+(\.\d+)?[bB]$", t, re.IGNORECASE): return t.upper()
    return None


# --- 4) UI ë° ìƒíƒœ ê´€ë¦¬ ---
st.title("ğŸ¤— Hugging Face ëª¨ë¸ íƒìƒ‰ê¸° (ì‹¤ì‹œê°„ ê²€ìƒ‰)")

# --- ìƒíƒœ ì´ˆê¸°í™” ---
if "page" not in st.session_state: st.session_state.page = 1
if "query_input" not in st.session_state: st.session_state.query_input = ""
if "sort_input" not in st.session_state: st.session_state.sort_input = "ë‹¤ìš´ë¡œë“œìˆœ (Downloads)"  # ê¸°ë³¸ê°’ ë‹¤ìš´ë¡œë“œìˆœ
if "search_params" not in st.session_state:
    st.session_state.search_params = {
        "query": "",
        "authors": [],
        "sort": "ë‹¤ìš´ë¡œë“œìˆœ (Downloads)",  # ê¸°ë³¸ê°’ ë‹¤ìš´ë¡œë“œìˆœ
        "text_gen_only": True,
        "cutoff_date": pd.to_datetime("2024-01-01").date(),
        "param_range": (0.0, 1000.0)
    }

# --- ì½œë°± ---
def update_search():
    st.session_state.search_params["query"] = st.session_state.query_input
    st.session_state.search_params["sort"] = st.session_state.sort_input
    st.session_state.page = 1

# --- ì‚¬ì´ë“œë°” í•„í„° ---
with st.sidebar:
    st.header("ğŸ” Filters")
    only_text_gen_widget = st.checkbox("text-generation ëª¨ë¸ ë³´ê¸°", value=st.session_state.search_params["text_gen_only"], help="ì´ ì˜µì…˜ì„ ì¼œë©´ HF tagì— 'text-generation'ì´ í¬í•¨ëœ ëª¨ë¸ë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì¼ë¶€ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì€ íƒœê·¸ê°€ ëˆ„ë½ë˜ì–´ ëª©ë¡ì— ë³´ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.caption(
    "âš ï¸ ì°¾ëŠ” ëª¨ë¸ì´ ë³´ì´ì§€ ì•Šìœ¼ë©´ ì²´í¬ë¥¼ í•´ì œí•´ ê²€ìƒ‰í•´ ë³´ì‹œê³ , "
    "íƒœê·¸ê°€ ì—†ë”ë¼ë„ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ HFì˜ ëª¨ë¸ ì¹´ë“œë¥¼ í™•ì¸í•´ ì£¼ì‹­ì‹œì˜¤."
    )
    
    priority_authors = ["naver-hyperclovax", "google", "openai", "meta-llama", "mistralai", "microsoft", "Qwen", "deepseek-ai", "moonshotai", "zai.org", "baidu", "LGAI-EXAONE", "upstage", "kakaocorp", "skt", "K-intelligence"]
    authors_widget = st.multiselect("ê¸°ì—…", options=priority_authors, default=st.session_state.search_params["authors"])
    

    cutoff_date_widget = st.date_input("ê¸°ì¤€ ë‚ ì§œ ì„ íƒ(ëª¨ë¸ ì¶œì‹œì¼)", value=st.session_state.search_params["cutoff_date"])

    st.subheader("ğŸ“ Parameter Size")
    param_range_widget = st.slider("Parameter Size ë²”ìœ„ (B)", 0.0, 1000.0, st.session_state.search_params["param_range"], 0.1)

    st.markdown("---")
    if st.button("ğŸ”„ í•„í„° ì ìš©í•˜ê¸°", use_container_width=True):
        st.session_state.search_params["authors"] = authors_widget
        st.session_state.search_params["text_gen_only"] = only_text_gen_widget
        st.session_state.search_params["cutoff_date"] = cutoff_date_widget
        st.session_state.search_params["param_range"] = param_range_widget
        st.session_state.page = 1
        st.rerun()

    # âœ… ìƒ‰ìƒ ë²”ë¡€ (Legend)
    ORANGE = "rgba(255, 165, 0, 0.15)"   # 100ë§Œ+
    YELLOW = "rgba(255, 255, 0, 0.15)"   # 50ë§Œ~100ë§Œ ë¯¸ë§Œ
    PURPLE = "rgba(145, 97, 237, 0.14)"  # êµ­ë‚´ íŠ¹ì • ì¡°ì§ + 5ë§Œ~50ë§Œ ë¯¸ë§Œ

    st.markdown("---")
    st.markdown("#### ìƒ‰ìƒ ë²”ë¡€")
    st.markdown(f"""
    <style>
      .legend-item {{ display:flex; align-items:center; gap:8px; margin:6px 0; font-size:13px; }}
      .legend-dot  {{ width:12px; height:12px; border-radius:50%; border:1px solid rgba(0,0,0,.18); }}
      .legend-note {{ font-size:12px; opacity:.75; margin-top:4px; line-height:1.4; }}
    </style>
    <div class="legend-item">
      <span class="legend-dot" style="background:{ORANGE}"></span>
      <span>ë‹¤ìš´ë¡œë“œ 100ë§Œ ì´ìƒ</span>
    </div>
    <div class="legend-item">
      <span class="legend-dot" style="background:{YELLOW}"></span>
      <span>ë‹¤ìš´ë¡œë“œ 50ë§Œâ€“100ë§Œ</span>
    </div>
    <div class="legend-item">
      <span class="legend-dot" style="background:{PURPLE}"></span>
      <span>ë‹¤ìš´ë¡œë“œ 5ë§Œ ì´ìƒ (êµ­ë‚´ ëª¨ë¸)</span>
    </div>
    <div class="legend-note">
      êµ­ë‚´ ê¸°ì—…: naver-hyperclovax, kakaocorp, lgai-exaone, upstage, skt, K-intelligence
    </div>
    """, unsafe_allow_html=True)

# --- ë©”ì¸ ê²€ìƒ‰ì°½/ì •ë ¬ ---
col1, col2 = st.columns([0.7, 0.3])
with col1:
    st.text_input("Search by name", placeholder="ğŸ” ëª¨ë¸ ID ë˜ëŠ” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (ì˜ˆ: meta-llama/Llama-2)", key="query_input", on_change=update_search)
with col2:
    st.selectbox("Sort by", ["ë‹¤ìš´ë¡œë“œìˆœ (Downloads)", "ì¸ê¸°ìˆœ (Likes)", "ìµœì‹ ìˆœ (Created At)", "íŒŒë¼ë¯¸í„° í¬ê¸°ìˆœ (Parameter Size)"], key="sort_input", on_change=update_search)

# --- ë°ì´í„° ë¡œë”© ë° í›„ì²˜ë¦¬ ---
search_args = st.session_state.search_params
base_df = search_models_on_hub(
    query=search_args["query"],
    authors=tuple(search_args["authors"]),
    sort=search_args["sort"],
    text_gen_only=search_args["text_gen_only"]
)

if base_df.empty:
    st.warning("ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ í›„ì²˜ë¦¬ í•„í„°
cutoff_ts = pd.Timestamp(search_args["cutoff_date"], tz="UTC")
final_df = base_df[(base_df["createdAt"].notna()) & (base_df["createdAt"] >= cutoff_ts)]
min_param, max_param = search_args["param_range"]
final_df = final_df[(final_df["param_size_numeric"] >= min_param) & (final_df["param_size_numeric"] <= max_param)]

# âœ… ì •ë ¬ ë¡œì§ - í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì •í™•íˆ ì •ë ¬
if search_args["sort"] == "ë‹¤ìš´ë¡œë“œìˆœ (Downloads)":
    final_df = final_df.sort_values(by="downloads", ascending=False)
elif search_args["sort"] == "ì¸ê¸°ìˆœ (Likes)":
    final_df = final_df.sort_values(by="likes", ascending=False)
elif search_args["sort"] == "ìµœì‹ ìˆœ (Created At)":
    final_df = final_df.sort_values(by="createdAt", ascending=False, na_position='last')
elif search_args["sort"] == "íŒŒë¼ë¯¸í„° í¬ê¸°ìˆœ (Parameter Size)":
    final_df = final_df.sort_values(by="param_size_numeric", ascending=True, na_position='last')  # ì‘ì€ ëª¨ë¸ë¶€í„°

# --- í˜ì´ì§€ë„¤ì´ì…˜ ë° ì¶œë ¥ ---
st.metric(label="Filtered Models", value=f"{len(final_df):,}")
st.markdown("---")

MODELS_PER_PAGE = 15
total = len(final_df)
total_pages = max(1, (total + MODELS_PER_PAGE - 1) // MODELS_PER_PAGE)
if st.session_state.page > total_pages:
    st.session_state.page = total_pages
start_idx = (st.session_state.page - 1) * MODELS_PER_PAGE
end_idx = st.session_state.page * MODELS_PER_PAGE
page_df = final_df.iloc[start_idx:end_idx]

# --- ëª©ë¡ ì¶œë ¥ (íŠ¹ì • ì¡°ì§ 5ë§Œ~50ë§Œ â†’ ì—°ë³´ë¼) ---
SPECIAL_AUTHORS = {
    "kakaocorp", "LGAI-EXAONE", "upstage", "skt", "K-intelligence", "naver-hyperclovax"
}

for _, row in page_df.iterrows():
    downloads = int(row["downloads"])
    likes = int(row["likes"])
    author = (row.get("author") or "").strip()

    # 1) ê¸°ë³¸ ë°°ê²½/í…Œë‘ë¦¬
    bg_color = "rgba(0,0,0,0.00)"
    border_color = "rgba(0,0,0,0.06)"

    # 2) íŠ¹ì • ì¡°ì§ + ë‹¤ìš´ë¡œë“œ 5ë§Œ~50ë§Œ â†’ ì—°ë³´ë¼
    if author in SPECIAL_AUTHORS and 50_000 <= downloads < 500_000:
        bg_color = "rgba(145, 97, 237, 0.14)"     # #9161ED with alpha
        border_color = "rgba(145, 97, 237, 0.35)"

    # 3) ì¼ë°˜ ì¡°ê±´ (ì—°ë³´ë¼ ì œì™¸)
    elif downloads >= 1_000_000:                   # 100ë§Œ ì´ìƒ â†’ ì£¼í™©
        bg_color = "rgba(255, 165, 0, 0.15)"
        border_color = "rgba(255, 165, 0, 0.35)"
    elif downloads >= 500_000:                     # 50ë§Œ~100ë§Œ ë¯¸ë§Œ â†’ ë…¸ë‘
        bg_color = "rgba(255, 255, 0, 0.15)"
        border_color = "rgba(255, 215, 0, 0.45)"

    created_str = row["createdAt"].strftime("%Y-%m-%d") if pd.notna(row["createdAt"]) else "N/A"
    license_str = extract_license(row["tags"])
    size_str = row["param_size"] or ""
    task_str = row.get("pipeline_tag", extract_task_from_tags(row["tags"]) or "N/A")
    region_label = "ğŸ‡°ğŸ‡· êµ­ë‚´ ëª¨ë¸" if author in SPECIAL_AUTHORS else "ğŸŒ í•´ì™¸ ëª¨ë¸"

    meta_parts = []
    if size_str: meta_parts.append(f"ğŸ“Š {size_str}")
    meta_parts.append(f"ğŸ“… Created {created_str}")
    if license_str: meta_parts.append(f"ğŸ“„ License: {license_str}")
    if task_str and task_str != "N/A": meta_parts.append(f"ğŸ¯ {task_str}")
    if region_label: meta_parts.append(f"{region_label}")


    meta_html = " â€¢ ".join(meta_parts)

    card_html = f"""
    <div style="
        background:{bg_color};
        border:1px solid {border_color};
        border-radius:12px;
        padding:16px 18px;
        margin:12px 0;
    ">
      <div style="display:flex; gap:16px; align-items:flex-start;">
        <div style="flex:1 1 auto;">
          <h4 style="margin:0 0 6px 0; font-weight:500;">
            <a href="https://huggingface.co/{row['modelId']}" target="_blank" style="text-decoration:none;">
              {row['modelId']}
            </a>
          </h4>
          <div style="opacity:.8; font-size:13px; margin-top:2px;">
            {meta_html}
          </div>
        </div>
        <div style="min-width:140px; text-align:right; line-height:1.45;">
          <div>â¬‡ï¸ {downloads:,}</div>
          <div>â¤ï¸ {likes:,}</div>
        </div>
      </div>
    </div>
    """
    st.markdown(card_html, unsafe_allow_html=True)




# --- í˜ì´ì§€ë„¤ì´ì…˜ ì»¨íŠ¸ë¡¤ ---
if not final_df.empty:
    p_cols = st.columns([1, 2, 1])
    if p_cols[0].button("â¬…ï¸ Previous", disabled=(st.session_state.page <= 1)):
        st.session_state.page -= 1
        st.rerun()
    p_cols[1].write(
        f"<div style='text-align: center;'>Page <b>{st.session_state.page}</b> of <b>{total_pages}</b></div>",
        unsafe_allow_html=True
    )
    if p_cols[2].button("Next â¡ï¸", disabled=(st.session_state.page >= total_pages)):
        st.session_state.page += 1
        st.rerun()
